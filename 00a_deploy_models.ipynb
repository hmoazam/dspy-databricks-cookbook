{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d418784f-7149-4969-b0b6-91dccfdda052",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deploy chat model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "926643ad-0a49-4648-a268-fd908df4279c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's deploy a provisioned throughput `meta-llama-3-1-3b-instruct` model which we'll use in our dspy program. The model will be hosted on a [Databricks Foundational Model Serving Endpoint](https://docs.databricks.com/en/machine-learning/foundation-models/index.html). Provisioned throughput endpoints can be created [using the API or the Serving UI](https://docs.databricks.com/aws/en/machine-learning/foundation-model-apis/deploy-prov-throughput-foundation-model-apis). You can easily swap out `meta-llama-3-1-3b-instruct` for [other providers or local models](https://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb) via the `dspy.LM` command, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9032a2b-49ef-44da-a674-e384fec658f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow>=2.18.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db1a1bd5-a15f-4d68-9425-85405436217d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "605264d4-22f4-48fa-a9d1-6bbd3169be6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.utils.databricks_utils.get_databricks_host_creds().host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2026383-bf8e-4dcd-963e-f3c773296d20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "734e29c5-9adc-467b-b604-af201ad14bb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config_file = \"config.yaml\"\n",
    "model_config = mlflow.models.ModelConfig(development_config=config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1a251e7-81da-4472-a9a6-32379660959f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the name of the MLflow endpoint\n",
    "chat_endpoint_name = model_config.get(\"chat_endpoint_name\")\n",
    "\n",
    "# Name of the registered MLflow model\n",
    "chat_model_name = model_config.get(\"chat_model_name\")\n",
    "\n",
    "# Get the latest version of the MLflow model\n",
    "chat_model_version = 1\n",
    "\n",
    "# Get the API endpoint and token for the current notebook context\n",
    "API_ROOT = mlflow.utils.databricks_utils.get_databricks_host_creds().host\n",
    "\n",
    "SECRET_SCOPE_NAME = model_config.get(\"secret_scope_name\")\n",
    "SECRET_SCOPE_KEY = model_config.get(\"secret_key\")\n",
    "\n",
    "API_TOKEN = dbutils.secrets.get(SECRET_SCOPE_NAME, SECRET_SCOPE_KEY)\n",
    "\n",
    "headers = {\"Context-Type\": \"text/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "optimizable_info = requests.get(\n",
    "  url=f\"{API_ROOT}/api/2.0/serving-endpoints/get-model-optimization-info/{chat_model_name}/{chat_model_version}\",\n",
    "  headers=headers).json()\n",
    "\n",
    "if 'optimizable' not in optimizable_info or not optimizable_info['optimizable']:\n",
    "  raise ValueError(\"Model is not eligible for provisioned throughput\")\n",
    "\n",
    "chunk_size = optimizable_info['throughput_chunk_size']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aeaf9ea-677b-40c4-aaee-7cc8e1e86c56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scale_to_zero = True\n",
    "\n",
    "# Minimum desired provisioned throughput\n",
    "min_provisioned_throughput = 0\n",
    "\n",
    "# Maximum desired provisioned throughput\n",
    "max_provisioned_throughput = 3 * chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdac354c-adf0-433f-846e-eaa4281f8a9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Send the POST request to create the serving endpoint\n",
    "data = {\n",
    "  \"name\": chat_endpoint_name,\n",
    "  \"config\": {\n",
    "    \"served_entities\": [\n",
    "      {\n",
    "        \"entity_name\": chat_model_name,\n",
    "        \"entity_version\": chat_model_version,\n",
    "        \"min_provisioned_throughput\": min_provisioned_throughput,\n",
    "        \"max_provisioned_throughput\": max_provisioned_throughput,\n",
    "        \"scale_to_zero_enabled\": scale_to_zero,\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "  url=f\"{API_ROOT}/api/2.0/serving-endpoints\", json=data, headers=headers\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05ac0105-5fdc-45df-8dd1-b72d00bb7b83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Deploy embedding model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e188fb1-24c1-4570-be2e-ca433b82fb31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the name of the MLflow endpoint\n",
    "embedding_endpoint_name = model_config.get(\"embedding_endpoint_name\")\n",
    "\n",
    "# Name of the registered MLflow model\n",
    "embedding_model_name = model_config.get(\"embedding_model_name\")\n",
    "\n",
    "# Get the latest version of the MLflow model\n",
    "embedding_model_version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c524005b-b0ff-446a-893d-1afbd0a83886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "optimizable_info = requests.get(\n",
    "  url=f\"{API_ROOT}/api/2.0/serving-endpoints/get-model-optimization-info/{embedding_model_name}/{embedding_model_version}\",\n",
    "  headers=headers).json()\n",
    "\n",
    "if 'optimizable' not in optimizable_info or not optimizable_info['optimizable']:\n",
    "  raise ValueError(\"Model is not eligible for provisioned throughput\")\n",
    "\n",
    "chunk_size = optimizable_info['throughput_chunk_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4ac64fd-2c0a-48b6-8b11-f38833104ead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scale_to_zero = True\n",
    "\n",
    "# Minimum desired provisioned throughput\n",
    "min_provisioned_throughput = 0\n",
    "\n",
    "# Maximum desired provisioned throughput\n",
    "max_provisioned_throughput = 3 * chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d74166fe-c865-4a99-9bdd-1a6705c95ac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Send the POST request to create the serving endpoint\n",
    "data = {\n",
    "  \"name\": embedding_endpoint_name,\n",
    "  \"config\": {\n",
    "    \"served_entities\": [\n",
    "      {\n",
    "        \"entity_name\": embedding_model_name,\n",
    "        \"entity_version\": embedding_model_version,\n",
    "        \"min_provisioned_throughput\": min_provisioned_throughput,\n",
    "        \"max_provisioned_throughput\": max_provisioned_throughput,\n",
    "        \"scale_to_zero_enabled\": scale_to_zero,\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "  url=f\"{API_ROOT}/api/2.0/serving-endpoints\", json=data, headers=headers\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 951504923291371,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "00a_deploy_models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
